\subsection{Umsetzung: Methoden zum Emotion Tracking} \label{MethodenEmotionTracking}
\subsubsection*{Theorethischer Inhalt}
Es gibt verschiedene Methoden, um die Emotion eines Nutzers während dessen Interaktion mit einer Maschine zu tracken. Im Folgenden werden die durch die Recherche gefundenen  Methoden erläutert:

\begin{itemize}
\item Hautwiderstand und Hauttemperatur:
Das Paper "A Suggestion to Improve User-Friendliness Based
on Monitoring Computer User’s Emotions" beschreibt, wie Emotionen eines Nutzers durch dessen Hauttemperatur und Hautwiderstand bestimmt werden können. Die Autoren nutzen dafür einen Temperatur- und Hautwiderstandssensor, die mit einem Arduino verbunden sind. Die Daten der Sensoren werden in einer SQLite Datenbank gespeichert und auf einer Android App ausgegeben. Die Autoren stellten fest, dass eine Änderung der Hauttemperatur bzw. des Hautwiderstands  auf eine Emotionsänderung des Nutzers zurückzuführen ist \cite{EmotionTrackingGSR}.

\item Blick: Die Autoren des Papers "Improving Human-Computer Interaction
by Gaze Tracking" untersuchten, wie der Blick des Nutzers zur Steuerung von Maschinen verwendet werden kann. Unter anderem wurde dargelegt, wie lange und welches Objekt von einem Nutzer betrachtet wird. Dabei wurde festgestellt, dass durch dieses Verfahren auch die Emotion eines Nutzers bestimmt werden kann. Beispielsweise verändert sich die Pupillengröße bei einer Emotionsänderung. Dabei nutzen die Autoren die integrierte Webcam in einem Laptop, um den Blick und somit die Emotionen zu tracken. Somit wird keine zusätzliche Hardware benötigt, wenn das Endgerät des Nutzers bereits eine Kamera integriert hat \cite{EmotionTrackingGaze}.

\item Gesichtsaudruck: Cloud Service Anbieter wie Amazon, IBM und Microsoft bieten Cognitive Services an, darunter auch ein Service zur Emotionserkennung. Abbildung \ref{fig:microsoftgestenerkennung} zeigt eine Live Demo des Service von Microsoft, dabei wird die Emotion "Überraschung" mit einer Wahrscheinlichkeit von 0,93 erkannt. Bei der Live Demo kann ein Bild hochgeladen oder direkt via Webcam aufgezeichnet werden. Der Service erkennt dann zuerst die Person bzw. Personen und bestimmt zu jeder Person, mit viel Prozent diese mit einer der vorgegeben Emotionen übereinstimmt.

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{Pictures/Microsoft_Gestenerkennung}
	\caption[Beispiel: Microsoft Azure Emotionserkennung]{Beispiel: Microsoft Azure Emotionserkennung \cite{MicrosoftAzure}}
	\label{fig:microsoftgestenerkennung}
\end{figure}


\item Sprachinformationen: Die Emotionen eines Menschen spiegeln sich in dessen Sprache wieder. Ein typisches Beispiel hierfür ist, wenn eine Person einen Vortrag hält und dabei sehr verunsichert und aufgeregt ist. Die Person spricht oft schnell und verspricht sich gegebenenfalls. Die Autoren des Papers "Speech emotion recognition approaches in human computer interactiong" untersuchten, wie genau können Emotionen eines Nutzers durch die Sprachinformationen bestimmt werden. Dabei extrahierten diese Muster aus mehreren Sprachsignal und bestimmten für diese Muster die Emotionen des Sprechers. Diese Informationen wurden dann verwendet, um eine künstliche Intelligenz zu trainieren. Somit sagen diese für ein beliebiges Sprachsignale die zugehörige Emotion vorher \cite{SpeechInformation}.
	
\end{itemize}

\vspace{3mm}
\subsubsection*{2. Aufgabe}
\begin{tabular}{c c }
	 Zeit: 10 min & Gruppenarbeit (4 Personen)\\
\end{tabular}
\vspace{1mm}

Im Workshop wollten wir gemeinsam mit allen Teilnehmern so viele Methoden wie möglich zum Emotion Tracking finden. Dazu wurden die in Kapitel \ref{MethodenEmotionTracking} genannten Methoden den Teilnehmern erstmal vorenthalten. Die Teilnehmer sollten im Internet über Methoden zum Tracken der Emotionen einer Person recherchieren. Dabei sollten die Methode in ihrer Gruppe diskutiert und  in einem Google Formular festgehalten werden.

\vspace{2mm}
\subsubsection*{Ergebnisse}
Es zeigt sich, dass die geplante Zeit für diese Aufgabe ausreichend war. Die Teilnehmer sammelten in den 10 Minuten 23 Methoden zum Emotionen Tracking. Die Methoden wurden mit den Teilnehmern diskutiert, falls ein Name einer Methode nicht selbsterklärend war, wurde der Verfasser gebeten, die Funktionsweise der Methode kurz zu erklären. Im Folgenden eine kurze Auflistung der Ergebnisse, die die Methoden aus Kapitel \ref{MethodenEmotionTracking} ergänzen:

\begin{itemize}
	\item Überwachung von Körperfunktionen
	\begin{itemize}
		\item Herzschlag
		\item Gehirnströme
		\item Atmung
		\item Muskelspannung
	\end{itemize}
	\item Eingabeverhalten auf dem Endgerät	
\end{itemize}

